{
  "model_version": "1.0",
  "debug_mode": false,
  "num_threads": 20,
  "set_cpu_affinity": true,
  "enable_intel_optimization": false,
  "enable_quantization": true,
  "enable_model_quantization": true,
  "enable_input_quantization": true,
  "quantization_dtype": "int8",
  "quantization_config": {
    "quantization_type": "int8",
    "quantization_mode": "dynamic_per_channel",
    "enable_cache": true,
    "cache_size": 972,
    "buffer_size": 1935,
    "use_percentile": true,
    "min_percentile": 0.1,
    "max_percentile": 99.9,
    "error_on_nan": true,
    "error_on_inf": true,
    "outlier_threshold": 3.0,
    "num_bits": 8,
    "optimize_memory": false
  },
  "enable_request_deduplication": true,
  "max_cache_entries": 5000,
  "cache_ttl_seconds": 300,
  "monitoring_window": 100,
  "enable_monitoring": true,
  "monitoring_interval": 10.0,
  "throttle_on_high_cpu": false,
  "cpu_threshold_percent": 95.0,
  "memory_high_watermark_mb": 8192,
  "memory_limit_gb": 60.4848892211914,
  "enable_batching": true,
  "batch_processing_strategy": "greedy",
  "batch_timeout": 0.1,
  "max_concurrent_requests": 40,
  "initial_batch_size": 128,
  "min_batch_size": 32,
  "max_batch_size": 384,
  "enable_adaptive_batching": false,
  "enable_memory_optimization": false,
  "enable_feature_scaling": true,
  "enable_warmup": true,
  "enable_quantization_aware_inference": false,
  "enable_throttling": false
}